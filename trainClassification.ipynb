{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from dataset import ModelNet40Dataset\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "filehandler = open('ModelNet40ProcessedDataset', 'rb') \n",
    "ModelNet40Data = pickle.load(filehandler)\n",
    "\n",
    "# print(len(ModelNet40Data.train['pcds']))\n",
    "def sample_data(data,batch_size):\n",
    "    total_N = len(data['pcds'])\n",
    "    indices = np.random.choice(total_N,batch_size,replace = False)\n",
    "    N_pts,d =  data['pcds'][0].shape\n",
    "    pcds = np.zeros((batch_size,N_pts,d))\n",
    "    labels = np.zeros(batch_size,dtype=int)\n",
    "    for i in range(batch_size):\n",
    "        pcd = data['pcds'][indices[i]]\n",
    "        #rotate pointcloud\n",
    "        a = np.random.rand()*math.pi\n",
    "        R = np.array([[math.cos(a),-math.sin(a),0.],\\\n",
    "              [math.sin(a),math.cos(a),0.],\\\n",
    "              [0.,0.,1.]])\n",
    "        pcd = pcd.dot(R)\n",
    "        #jitter\n",
    "        pcd += np.random.normal(0,0.02,size=pcd.shape)      \n",
    "        pcds[i,:,:] = pcd\n",
    "        labels[i] = int(data['labels'][indices[i]])\n",
    "    return pcds,labels\n",
    "    \n",
    "def get_data(data):\n",
    "    total_N = len(data['pcds'])\n",
    "    indices = np.arange(total_N)\n",
    "    N_pts,d =  data['pcds'][0].shape\n",
    "    pcds = np.zeros((total_N,N_pts,d))\n",
    "    labels = np.zeros(total_N,dtype=int)\n",
    "    for i in range(total_N):\n",
    "        pcds[i,:,:] = data['pcds'][indices[i]]\n",
    "        labels[i] = int(data['labels'][indices[i]])\n",
    "    return pcds,labels\n",
    "\n",
    "def compute_accuracy(preds,target):\n",
    "    tmp = preds.max(1).indices == target\n",
    "    return torch.sum(tmp).detach().cpu().numpy()/target.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparameters\n",
    "N_CLASSES = 40\n",
    "EPOCHS = 1000#2000\n",
    "BATCH_SIZE = 32\n",
    "INIT_LR = 0.001\n",
    "MOMENTUM = 0.9\n",
    "LR_STEP = 20\n",
    "SCHEDULER_GAMMA = 0.5\n",
    "TEST_EVERY = 1\n",
    "REG_WEIGHT = 0.001\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = PointNetClassification(N_CLASSES).to(device)\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=INIT_LR)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEP, gamma=SCHEDULER_GAMMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##training loop\n",
    "train_losses = []\n",
    "train_iterations = []\n",
    "test_losses = []\n",
    "test_iterations = []\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    net.train() \n",
    "    #load the batch of data\n",
    "    data,labels = sample_data(ModelNet40Data.train,BATCH_SIZE)\n",
    "    data = torch.from_numpy(data).float().to(device)\n",
    "    labels = torch.from_numpy(labels).to(device)\n",
    "    \n",
    "    #compute the loss\n",
    "    preds,M2 = net(data)\n",
    "    loss = criterion(preds,labels)\n",
    "    \n",
    "    #add transformation matrix regularization loss\n",
    "    I = torch.eye(64).unsqueeze(0).to(device)\n",
    "    loss2 = torch.mean(torch.norm(torch.bmm(M2,M2.transpose(2,1)) - I, dim=(1,2)))    \n",
    "    loss += REG_WEIGHT*loss2\n",
    "    \n",
    "    train_losses.append(loss.detach().cpu())\n",
    "    train_iterations.append(epoch)\n",
    "    train_accuracy = compute_accuracy(preds,labels)\n",
    "    #step the optimizer\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    if epoch%TEST_EVERY == 0:\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            #load the batch of test data (batch size couldn't be too big)\n",
    "            data,labels = sample_data(ModelNet40Data.test,32)\n",
    "            data = torch.from_numpy(data).float().to(device)\n",
    "            labels = torch.from_numpy(labels).to(device)\n",
    "            \n",
    "            preds,M2 = net(data)\n",
    "            test_loss = criterion(preds,labels)\n",
    "            #add transformation matrix regularization loss\n",
    "            I = torch.eye(64).unsqueeze(0).to(device)\n",
    "            test_loss2 = torch.mean(torch.norm(torch.bmm(M2,M2.transpose(2,1)) - I, dim=(1,2)))    \n",
    "            test_loss += REG_WEIGHT*test_loss2\n",
    "\n",
    "            test_losses.append(test_loss.detach().cpu())\n",
    "            test_iterations.append(epoch)\n",
    "            test_accuracy = compute_accuracy(preds,labels)\n",
    "            print('Epoch:',epoch, ';train and test accuracies:',train_accuracy,test_accuracy)\n",
    "\n",
    "#     clear_output()\n",
    "    plt.plot(train_iterations, train_losses, 'b',test_iterations, test_losses, 'r')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss') \n",
    "    plt.legend(['Train','Test'])\n",
    "    plt.title('Epoch vs Loss')\n",
    "#     plt.show()\n",
    "    plt.savefig(\"./cls_losses.png\") # save graph for training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###save stuff\n",
    "# folder = 'results/'\n",
    "# torch.save(net.state_dict(), folder+'classification_model')\n",
    "# filehandler = open(folder+'classification_train_iterations', 'wb') \n",
    "# pickle.dump(train_iterations, filehandler)\n",
    "# filehandler = open(folder+'classification_train_losses', 'wb') \n",
    "# pickle.dump(train_losses, filehandler)\n",
    "# filehandler = open(folder+'classification_test_iterations', 'wb') \n",
    "# pickle.dump(test_iterations, filehandler)\n",
    "# filehandler = open(folder+'classification_test_losses', 'wb') \n",
    "# pickle.dump(test_losses, filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot training loss\n",
    "import pickle\n",
    "\n",
    "\n",
    "filehandler = open(folder+'classification_train_iterations', 'rb') \n",
    "train_iterations = pickle.load(filehandler)\n",
    "filehandler = open(folder+'classification_train_losses', 'rb') \n",
    "train_losses = pickle.load(filehandler)\n",
    "filehandler = open(folder+'classification_test_iterations', 'rb') \n",
    "test_iterations = pickle.load(filehandler)\n",
    "filehandler = open(folder+'classification_test_losses', 'rb') \n",
    "test_losses = pickle.load(filehandler)\n",
    "\n",
    "import os,math,numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate\n",
    "\n",
    "matplotlib.rcParams['axes.linewidth'] = 5\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rc('font',size=35)\n",
    "\n",
    "iter=train_iterations\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(1,1,1)\n",
    "fig.set_size_inches(12*1.5,8*1.5)\n",
    "xnew=np.linspace(min(iter),max(iter),200)  \n",
    "test_loss_spline=scipy.interpolate.CubicSpline(iter,test_losses)\n",
    "test_data = test_loss_spline(xnew)\n",
    "\n",
    "ln=ax.plot(xnew,test_data,label=\"Test Loss\",linewidth=5,color='#ff7f0e')\n",
    "ax.tick_params(axis='y',colors='#ff7f0e')\n",
    "\n",
    "ax2=ax.twinx()\n",
    "xnew=np.linspace(min(iter),max(iter),200)  \n",
    "train_loss_spline=scipy.interpolate.CubicSpline(iter,train_losses)\n",
    "train_data = train_loss_spline(xnew)\n",
    "ln+=ax2.plot(xnew,train_data,label=\"Train Loss\",linewidth=5,color='#1f77b4')\n",
    "ax2.tick_params(axis='y',colors='#1f77b4')\n",
    "ax2.spines['right'].set_color('#1f77b4')\n",
    "ax2.spines['left'].set_color('#ff7f0e')\n",
    "\n",
    "labs=[l.get_label() for l in ln]\n",
    "ax.legend(ln,labs,loc=0)\n",
    "\n",
    "#ax.set_ylabel(\"Value\")\n",
    "ax.set_xlabel(\"#Iteration\")\n",
    "plt.savefig(\"Iteration.pdf\",bbox_inches='tight',pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy on the entire test data\n",
    "\n",
    "net = PointNetClassification(N_CLASSES).to(device)\n",
    "net.load_state_dict(torch.load('results/classification_model'))\n",
    "net.eval()\n",
    "\n",
    "test_N = len(ModelNet40Data.test['pcds'])\n",
    "\n",
    "class_total = np.zeros(N_CLASSES)\n",
    "class_correct = np.zeros(N_CLASSES)\n",
    "#entire test data too larget to load in one batch, do one by one instead\n",
    "for i in range(test_N):\n",
    "    pcds = np.zeros((1,1024,3))\n",
    "    labels = np.zeros(1,dtype=int)\n",
    "    pcds[0,:,:] = ModelNet40Data.test['pcds'][i]\n",
    "    labels[0] = int(ModelNet40Data.test['labels'][i])\n",
    "\n",
    "    data = torch.from_numpy(pcds).float().to(device)\n",
    "    labels = torch.from_numpy(labels).to(device)\n",
    "\n",
    "    preds,M2 = net(data)\n",
    "    prediction = preds.max(1).indices.cpu().detach().numpy()[0]\n",
    "    target = labels[0].cpu().detach().numpy()\n",
    "    class_total[target] += 1\n",
    "    if prediction == target:\n",
    "        class_correct[target] += 1\n",
    "print(class_total)\n",
    "print(class_correct)\n",
    "\n",
    "avg_class = 0.\n",
    "for i in range(N_CLASSES):\n",
    "    avg_class += class_correct[i]/class_total[i]\n",
    "    \n",
    "print('total_accuracy:',sum(class_correct)/sum(class_total))\n",
    "print('average_class_accuracy:',avg_class/N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
